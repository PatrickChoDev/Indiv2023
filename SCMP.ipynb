{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48146f4-fb4a-4631-acb7-364776a9fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_EMBBED_ID = 'sentence-transformers/gtr-t5-xl'\n",
    "HF_MODEL_ID = 'google/flan-ul2'\n",
    "USE_HF_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e8cf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import getpass\n",
    "dotenv.load_dotenv()\n",
    "ENV = dotenv.dotenv_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e2b07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a different task than the one specified in the repository. Be sure to know what you're doing :)\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface_hub import HuggingFaceHubEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "api_key= ENV['HUGGINGFACEHUB_API_TOKEN'] if ENV['HUGGINGFACEHUB_API_TOKEN'] else getpass.getpass(\"Hugging Face API Access Token: \"),\n",
    "\n",
    "embedding = HuggingFaceHubEmbeddings() if USE_HF_MODEL else OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8bd876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=HF_MODEL_ID\n",
    ") if USE_HF_MODEL else ChatOpenAI()\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "207cb06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='would like me to clarify?\"', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='Short-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(query=\"Waht date is today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230debb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful AI assistant. Use the following pieces of context to answer the question at the end.\n",
    "If the question is not related to the context, politely respond that you are teached to only answer questions that are related to the context.\n",
    "If you don't know the answer, just say you don't know. DO NOT try to make up an answer. Try to make the title for every answer if it is possible. Answer in markdown.\n",
    "Use as much detail as possible when responding and try to make answer in markdown format as much as possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "{chat_history}\n",
    "Question: {question}\n",
    "Answer in markdown format:\n",
    "  \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"chat_history\", \"question\", \"context\"], template=template)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory,combine_docs_chain_kwargs={\"prompt\": prompt}, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a91c1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the mathematics', 'chat_history': '', 'answer': ' '}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({'question':\"What is the mathematics\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842bfec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
