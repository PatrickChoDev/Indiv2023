{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f48146f4-fb4a-4631-acb7-364776a9fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_EMBBED_ID = 'mistralai/Mistral-7B-v0.1'\n",
    "HF_MODEL_ID = 'LACAI/DialoGPT-small-SGD'\n",
    "USE_HF_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e8cf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import getpass\n",
    "dotenv.load_dotenv()\n",
    "ENV = dotenv.dotenv_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42e2b07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a different task than the one specified in the repository. Be sure to know what you're doing :)\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface_hub import HuggingFaceHubEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "api_key= ENV['HUGGINGFACEHUB_API_TOKEN'] if ENV['HUGGINGFACEHUB_API_TOKEN'] else getpass.getpass(\"Hugging Face API Access Token: \"),\n",
    "\n",
    "embedding = HuggingFaceHubEmbeddings() if USE_HF_MODEL else OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8bd876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=HF_MODEL_ID, model_kwargs={\"temperature\": 0.5}\n",
    ") if USE_HF_MODEL else ChatOpenAI()\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "230debb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful AI assistant. Use the following pieces of context to answer the question at the end.\n",
    "If the question is not related to the context, politely respond that you are teached to only answer questions that are related to the context.\n",
    "If you don't know the answer, just say you don't know. DO NOT try to make up an answer. Try to make the title for every answer if it is possible. Answer in markdown.\n",
    "Use as much detail as possible when responding and try to make answer in markdown format as much as possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "{chat_history}\n",
    "Question: {question}\n",
    "Answer in markdown format:\n",
    "  \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"chat_history\", \"question\", \"context\"], template=template)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory,combine_docs_chain_kwargs={\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a91c1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the mathematics', 'chat_history': '', 'answer': '!!'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({'question':\"What is the mathematics\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842bfec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
